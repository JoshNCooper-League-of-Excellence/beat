import fmt::{
  format,
  printlnf,
  Format_Options,
};

import map::Map;

import fs::File;

// line, column, filename,
alias SourceLocation :: (String, u32, u32);

impl SourceLocation {
  to_string :: fn(self) -> String {
    return format("%:%:%", self, Format_Options::default());
  }
}
LexError :: struct {
  location: SourceLocation,
  message:  String,
}

TokenType :: enum {
  Eof,

  Add,
  Sub,
  Div,
  Mul,
  Assign,
  Not,
  Comma,
  
  OpenParen,
  CloseParen,
  
  OpenCurly,
  CloseCurly,

  OpenBracket,
  CloseBracket,

  Semi,

  LT,
  LTE,
  GT,
  GTE,
  EQ,
  NEQ,
  Dot,

  Number,
  String,

  Identifier,

  If,
  For,
  In,
  While,
  Make,
  
  Return,
  Fn,
  VarLocal,
  VarEnv,
}

Token :: struct {
  type: TokenType,
  value: Option!<String>,
  location: SourceLocation,
}

Lexer :: struct {
  input: String,
  location: SourceLocation,
  buffer: Token[],
  position: u32,

  keywords: Map!<str, TokenType>,
}

impl Lexer {
  new :: fn(path: String) -> #self {
    mut keywords: Map!<str, TokenType>;

    keywords.insert("if", TokenType::If);
    keywords.insert("return", TokenType::Return);
    keywords.insert("fn", TokenType::Fn);
    
    keywords.insert("var", TokenType::VarLocal);
    keywords.insert("var:local", TokenType::VarLocal);

    keywords.insert("var:env", TokenType::VarEnv);
    keywords.insert("while", TokenType::While);
    keywords.insert("for", TokenType::For);
    keywords.insert("in", TokenType::In);
    keywords.insert("make", TokenType::Make);

    return .{
      input: File::read_all(path.as_str()).unwrap(),
      location: (path, 0, 0),
      keywords: keywords,
    };
  }

  advance :: fn(*mut self, new_line: bool) {
    if new_line {
      self.location.1++;
      self.location.2 = 1;
    } else {
      self.location.2++;
    }
    self.position++;
  }

  get_next_char :: fn(*mut self, ch: *mut u8) {
    self.advance(false);
    *ch = self.input[self.position];
  }

  get_token :: fn(*mut self) -> Result!<Token, LexError> {
    alias Result :: Result!<Token, LexError>;
    mut token: Token;

    token.type = TokenType::Eof;

    while self.position < self.input.length {
      mut ch := self.input[self.position];

      if ch == '\n' {
        self.advance(true);
        continue;
      }

      if ch == ' ' || ch == '\t' {
        self.advance(false);
        continue;
      }

      if ch == '_' || isalpha(ch) {
        start := self.position;
        while ch == '_' || isalpha(ch) || ch == ':' {
          self.get_next_char(&mut ch);
        }
        end := self.position;

        length := end - start;

        token.value = Some(String.{
          data: strndup(self.input.data + start, length),
          length: length,
          capacity: length,
        });

        token.type = TokenType::Identifier;

        mut value := token.value.unwrap();

        keyword := self.keywords.get(value.as_str());

        // TODO: we can deinit the string here, but we could just avoid allocating it all together.
        if keyword.is_some() {
          token.type = keyword.unwrap();
          value.deinit();
          token.value = None();
        }

        break;
      } else if isdigit(ch) {
        start := self.position;
        while isdigit(ch) {
          self.get_next_char(&mut ch);
        }
        end := self.position;
        length := end - start;

        token.value = Some(String.{
          data: strndup(self.input.data + start, length),
          length: length,
          capacity: length,
        });

        token.type = TokenType::Number;
        break;
      } else {
        type := switch ch {
          '+' => TokenType::Add,
          '-' => TokenType::Sub,
          '/' => TokenType::Div,
          '*' => TokenType::Mul,
          '=' => TokenType::Assign,
          '!' => TokenType::Not,
          ',' => TokenType::Comma,
          '.' => TokenType::Dot,
          '(' => TokenType::OpenParen,
          ')' => TokenType::CloseParen,
          '{' => TokenType::OpenCurly,
          '}' => TokenType::CloseCurly,
          '[' => TokenType::OpenBracket,
          ']' => TokenType::CloseBracket,
          ';' => TokenType::Semi,
          else => TokenType::Eof,
        };

        if type != TokenType::Eof {
          self.advance(false);
          token.type = type;
          break;
        }


        start := self.position;
        while ispunct(ch) {
          self.get_next_char(&mut ch);
        }
        end := self.position;
        length := end - start;

        mut value := String.{
          data: strndup(self.input.data + start, length),
          length: length,
          capacity: length,
        };

        token.type = switch value.as_str() {
          "=" => TokenType::Assign,
          "<" => TokenType::LT,
          ">" => TokenType::GT,
          ">=" => TokenType::GTE,
          "<=" => TokenType::LTE,
          "==" => TokenType::EQ,
          "!=" => TokenType::NEQ,
        };

        value.deinit();

        break;
      }
    }

    return Result::Ok(token);
  }
}

impl Lexer {
  fill_buffer :: fn(*mut self) {
    while self.buffer.length < 8 {
      token := self.get_token();
      if token.is_err() {
        break;
      }
      self.buffer.push(token.unwrap());
    }
  }

  eat :: fn(*mut self) -> Result!<Token, LexError> {
    if self.buffer.length == 0 {
      self.fill_buffer();
    }
    return Result!<Token, LexError>::Ok(self.buffer.pop_front());
  }

  peek :: fn(*mut self) -> Token {
    if self.buffer.length == 0 {
      self.fill_buffer();
    }
    return self.buffer[0];
  }

  expect :: fn(*mut self, expected: TokenType) -> Result!<Token, LexError> {
    token_result := self.eat();

    if (token_result.is_err()) {
      return token_result.propagate();
    }

    token := token_result.unwrap();

    if token.type != expected {
      return Result!<Token, LexError>::Err(LexError.{
        location: token.location,
        message: format("Expected token type: %, but got: %", (expected, token.type), Format_Options::default()),
      });
    }
    return Result!<Token, LexError>::Ok(token);
  }
}